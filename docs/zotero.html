<!DOCTYPE html>
<html>
    <head>
        <title>D Love</title>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <link rel="stylesheet" type="text/css" href="style.css" />
    </head>
    <body>
        <h1> Dannika Love's Website (Portfolio) </h1>
        <nav class="list">
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html">About</a></li>
                <li><a href="gallery.html">Gallery</a></li>
                <li><a href="resume.html">Resume</a></li>
                <li><a href="reflection.html">Reflection</a></li>
                <li><a href="textPatterns.html">Text Patterns</a></li>
                <li><a href="gameAnalysis.html">Game Analysis</a></li>
                <li><a href="javaScriptPractice.html">Java Script Practice</a></li>
                <li><a href="zotero.html">Zotero Analysis of AI</a></li>
            </ul>
        </nav>
        <header>
            <h1>AI and Misinformation</h1>
            <p>Exploring how artificial intelligence shapes, spreads, and combats misinformation
                online</p>
        </header>
            <section>
                <h2>Introduction</h2>
                <p> Artificial intelligence is transforming communication and media, but it also
                    plays a major role in spreading misinformation. From deepfakes and algorithmic
                    amplification to biased content moderation, AI technologies affect how people
                    understand truth online. This guide introduces the issue, highlights current
                    research, and points to resources that explain different perspectives. </p>
            </section>
            <section>
                <h2>Why This Issue Matters</h2>
                <p> AI-driven misinformation influences public opinion, political trust, and even
                    democratic stability. As a student in <strong>Digital Media, Arts, and
                        Technology</strong>, understanding these tools is crucial— not just for
                    building ethical technology, but for helping others navigate online information
                    responsibly. </p>
            </section>
            <section>
                <h2>Different Perspectives on the Issue</h2>
                <h3>1. Deepfakes and Media Manipulation</h3>
                <p> AI-generated deepfakes are becoming increasingly realistic, challenging our
                    ability to trust visual media. These manipulated videos can be used to spread
                    false information, impersonate individuals, or distort political messages. </p>
                <h3>2. Algorithmic Amplification</h3>
                <p> Algorithms decide what content we see—and often boost content that is emotional,
                    moral, or divisive. This can unintentionally promote misleading or extremist
                    material while shaping our perception of public opinion. </p>
                <h3>3. Government and Platform Regulation</h3>
                <p> Countries around the world are beginning to address AI and misinformation
                    through legislation. New bills aim to regulate transparency, content labeling,
                    and accountability in AI systems used for social media or political influence. </p>
                <h3>4. Psychological and Social Factors</h3>
                <p> Human biases—such as copying prestigious or emotionally charged information—make
                    us especially vulnerable to misinformation. AI platforms can exploit these
                    tendencies, accelerating polarization and distrust. </p>
            </section>
            <section>
                <h2>Curated Resources and Annotations</h2>
                <div class="source">
                    <h3>1. “How Deepfakes Are Changing Truth and Media” — <em>National
                            Geographic</em></h3>
                    <p> This article explores how deepfake technology blurs the line between truth
                        and fabrication in visual media. It’s useful because it connects technical
                        details (like GANs) with ethical and journalistic concerns. The examples
                        show how misinformation spreads faster when people can no longer trust what
                        they see. </p>
                    <a href="https://www.nationalgeographic.com/science/article/deepfakes"
                        target="_blank">Read more →</a>
                </div>
                <div class="source">
                    <h3>2. “AI Legislation Tracker” — <em>Brookings Institution</em></h3>
                    <p> This policy tracker summarizes how governments worldwide are drafting laws
                        about AI transparency and misinformation. It provides a clear overview of
                        national strategies and ongoing debates about regulating algorithms. It’s
                        especially useful for understanding how ethical design and law intersect. </p>
                    <a href="https://www.brookings.edu/research/ai-legislation-tracker/"
                        target="_blank">Read more →</a>
                </div>
                <div class="source">
                    <h3>3. “YouTube’s AI-Generated Content Disclosure Rules” — <em>The
                        Verge</em></h3>
                    <p> The article explains YouTube’s new rules requiring creators to disclose
                        AI-generated material. It’s an example of how tech companies are taking
                        early steps toward transparency. This resource is valuable because it
                        connects policy ideas to real platform changes. </p>
                    <a href="https://www.theverge.com/" target="_blank">Read more →</a>
                </div>
                <div class="source">
                    <h3>4. “Algorithmic Amplification and Misinformation” — <em>Nature</em></h3>
                    <p> This research paper explains how engagement-based recommendation systems
                        promote divisive or misleading content. It’s helpful for understanding the
                        science of social media influence and its connection to political
                        polarization. </p>
                    <a href="https://www.nature.com/" target="_blank">Read more →</a>
                </div>
                <div class="source">
                    <h3>5. “Social Learning and PRIME Information” — <em>PNAS</em></h3>
                    <p> This article introduces the concept of <strong>PRIME
                        information</strong>—Prestigious, In-group, Moral, and Emotional content. It
                        explains how algorithms amplify natural human learning biases, making
                        misinformation more appealing and viral. The authors also suggest possible
                        reforms, such as transparency tools and limiting PRIME amplification. </p>
                    <a href="https://www.pnas.org/" target="_blank">Read more →</a>
                </div>
            </section>
            <section>
                <h2>Learn More and Explore</h2>
                <ul>
                    <li>
                        <a href="https://alltechishuman.org/resources" target="_blank">All Tech is
                            Human – Content Moderation Resources</a>
                    </li>
                    <li>
                        <a href="https://manipulatedmedia.org/" target="_blank">Manipulated Media
                            Detection – Web Essay</a>
                    </li>
                    <li>
                        <a href="https://www.futureoflife.org/" target="_blank">Future of Life
                            Institute – AI Policy & Ethics</a>
                    </li>
                </ul>
            </section>
        <footer class="copyright">
            <p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/">
                <a property="dct:title" rel="cc:attributionURL"
                    href="http://dal5842.github.io/Portfolio/">Dannika's Portfolio</a> by <a
                        rel="cc:attributionURL dct:creator" property="cc:attributionName"
                        href="https://github.com/dal5842/Portfolio">Dannika Love</a> is licensed under
                <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1"
                    target="_blank" rel="license noopener noreferrer" style="display:inline-block;"
                    >CC BY-NC-ND 4.0 <img
                        style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
                        src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"
                        alt="" />
                    <img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
                        src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"
                        alt="" />
                    <img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
                        src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"
                        alt="" />
                    <img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"
                        src="https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1"
                        alt="" /></a></p>
        </footer>
    </body>
</html>
